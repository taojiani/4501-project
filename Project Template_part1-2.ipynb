{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3aa78f5",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13859cac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e8ffe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "#!pip install geoalchemy2\n",
    "#!pip install geopandas\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ec74f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(data)\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"aQ9WaK19vkxI27LB8CNNI6E7Y\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/resource\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"real_estate_nyc\"  # Replace with your actual database name\n",
    "DB_USER = \"4501_project_team\"  # Replace with your actual database user\n",
    "#DB_USER = \"jt3467\" \n",
    "DB_URL = f\"postgres+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dfeb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a2b9d",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e99008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def download_nyc_geojson_data(url, force=False):\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    # Create a Path object for the filename\n",
    "    filename = DATA_DIR / url_path\n",
    "\n",
    "    # Check if the file exists or if force download is requested\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        # Create directories if they don't exist\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Write the content to a file\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(response.json(), f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a212f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url, app_token, force=False):\n",
    "    headers = {\n",
    "        'X-App-Token': app_token,\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    filename = DATA_DIR / url_path\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(response.json(), f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d86085b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(ZIPCODE_DATA_FILE):\n",
    "  # Load the shapefile using geopandas\n",
    "    gdf_nyc_zipcodes = gpd.read_file(ZIPCODE_DATA_FILE)\n",
    "   # print(gdf_nyc_zipcodes.crs)  \n",
    "   # print(gdf_nyc_zipcodes.head()) \n",
    "   # gdf_nyc_zipcodes.plot()\n",
    "   # plt.show()\n",
    "   # Define the columns to keep. For the purpose of this example, we'll assume the project does not require building-specific ZIP codes, FIPS codes, or URLs.\n",
    "    columns_to_keep = [\n",
    "    'ZIPCODE', 'PO_NAME', 'POPULATION', 'AREA', 'STATE', 'COUNTY', 'geometry']\n",
    "\n",
    "  # Remove unnecessary columns\n",
    "    gdf_nyc_zipcodes_cleaned = gdf_nyc_zipcodes[columns_to_keep]\n",
    "\n",
    "# Check for and remove any invalid geometries\n",
    "    gdf_nyc_zipcodes_cleaned = gdf_nyc_zipcodes_cleaned[~gdf_nyc_zipcodes_cleaned.is_empty & gdf_nyc_zipcodes_cleaned.is_valid]\n",
    "\n",
    "# Normalize column names to lowercase with underscores\n",
    "    gdf_nyc_zipcodes_cleaned.columns = gdf_nyc_zipcodes_cleaned.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    return gdf_nyc_zipcodes_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ddd749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    # Download the data using SoQL filters for the correct date range\n",
    "    # This may involve constructing a URL with query parameters\n",
    "    #data_311_url = BASE_NYC_DATA_URL + NYC_DATA_311\n",
    "    #data_311_file = download_nyc_geojson_data(data_311_url)\n",
    "    \n",
    "    data_311_file = r\"/Users/jz/Desktop/4501project/311_request_data.csv\"\n",
    "    #data_311_file = r\"C:\\Users\\Tzz\\Desktop\\4501project\\311_request_data.csv\"\n",
    "    def_311 = gpd.read_file(data_311_file)\n",
    "    df_311_columns_to_keep = [\n",
    "    'Unique Key', 'Created Date',  'Agency', 'Complaint Type', \n",
    "    'Descriptor', 'Location Type', 'Incident Zip', 'City', 'Borough', \n",
    "    'Latitude', 'Longitude'\n",
    "]\n",
    "\n",
    "    df_311_cleaned = def_311[df_311_columns_to_keep]\n",
    "\n",
    "    df_311_cleaned = df_311_cleaned.dropna(subset=df_311_columns_to_keep)\n",
    "\n",
    "    df_311_cleaned.columns = df_311_cleaned.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    return df_311_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ce62363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "     # Download the data\n",
    "    #tree_data_url = BASE_NYC_DATA_URL + NYC_DATA_TREES\n",
    "    #tree_datafile = download_nyc_geojson_data(tree_data_url)\n",
    "    \n",
    "    tree_datafile =r\"/Users/jz/Desktop/4501project/2015StreetTreesCensus_TREES.csv\"\n",
    "    #tree_datafile =r\"C:\\Users\\Tzz\\Desktop\\4501project\\2015StreetTreesCensus_TREES.csv\"\n",
    "    # Load the data\n",
    "    gdf_tree = gpd.read_file(tree_datafile)\n",
    "    # print(gdf_tree.crs)\n",
    "    # print(gdf_tree.head()) \n",
    "    # gdf_tree.plot() \n",
    "    # plt.show()\n",
    "    # Define the columns to keep. For the purpose of this example, we'll assume the project does not require building-specific ZIP codes, FIPS codes, or URLs.\n",
    "    columns_to_keep = [\n",
    "    'tree_id', 'block_id', 'status', 'address', 'zipcode', 'zip_city',\n",
    "    'Latitude','longitude','x_sp','y_sp','geometry'\n",
    "    ]\n",
    "\n",
    "# Remove unnecessary columns\n",
    "    gdf_tree_cleaned = gdf_tree[columns_to_keep]\n",
    "\n",
    "# Check for and remove any invalid geometries\n",
    "    gdf_tree_cleaned = gdf_tree_cleaned[~gdf_tree_cleaned.is_empty & gdf_tree_cleaned.is_valid]\n",
    "\n",
    "# Normalize column names to lowercase with underscores\n",
    "    gdf_tree_cleaned.columns = gdf_tree_cleaned.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    return gdf_tree_cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14c77d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data():\n",
    "    df_zillow = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "    zillow_columns_to_keep = [\n",
    "    'RegionID', 'RegionName', 'City', 'State', 'Metro', 'CountyName', \n",
    "    \"2023-01-31\",\"2023-02-28\",\"2023-03-31\",\"2023-04-30\",\"2023-05-31\",\n",
    "    \"2023-06-30\",\"2023-07-31\",\"2023-08-31\",\"2023-09-30\"\n",
    "]\n",
    "    # Filter the dataframe to keep only the selected columns\n",
    "    df_zillow_cleaned = df_zillow[zillow_columns_to_keep]\n",
    "\n",
    "# Handle missing values by filling with the previous value in the column, as a simple method of imputation\n",
    "    df_zillow_cleaned = df_zillow_cleaned.fillna(method='ffill', axis=1)\n",
    "\n",
    "# Normalize column names to lowercase with underscores\n",
    "    df_zillow_cleaned.columns = df_zillow_cleaned.columns.str.lower().str.replace('-', '_')\n",
    "    \n",
    "    return df_zillow_cleaned\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f32ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e264becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486dd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "zipcode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b76226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee41c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data = download_and_clean_311_data()\n",
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c14df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    " geodf_tree_data= download_and_clean_tree_data()\n",
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d170f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data = load_and_clean_zillow_data()\n",
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4608b9d6",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc914f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_new_postgis_database(username, db_name):\n",
    "    \"\"\"\n",
    "    Create a new PostgreSQL database and enable the PostGIS extension.\n",
    "\n",
    "    - username (str): The username of the PostgreSQL user.\n",
    "    - db_name (str): The name of the new database created.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new PostgreSQL database\n",
    "    create_db_command = f\"createdb {db_name} --username={username}\"\n",
    "    !{create_db_command}\n",
    "\n",
    "    # Enable the PostGIS extension for the created database\n",
    "    enable_postgis_command = f\"psql --dbname={db_name} --username={username} -c 'CREATE EXTENSION postgis;'\"\n",
    "    !{enable_postgis_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50808e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_new_postgis_database(DB_USER, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433bb55",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acada32",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194661b",
   "metadata": {},
   "source": [
    "#### Using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61671ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the SQL statements to create your 4 tables\n",
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "CREATE TABLE nyc_zipcodes (\n",
    "    zipcodes_id SERIAL PRIMARY KEY,\n",
    "    zipcode VARCHAR(10),\n",
    "    po_name VARCHAR(255),\n",
    "    population INTEGER,\n",
    "    area FLOAT,\n",
    "    state VARCHAR(255),\n",
    "    county VARCHAR(255),\n",
    "    geometry GEOMETRY(Point, 4326)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "CREATE TABLE nyc_311 (\n",
    "    complaints_id SERIAL PRIMARY KEY,\n",
    "    unique_key VARCHAR(255),\n",
    "    created_date TIMESTAMP,\n",
    "    agency VARCHAR(255),\n",
    "    complaint_type VARCHAR(255),\n",
    "    descriptor VARCHAR(255),\n",
    "    location_type VARCHAR(255),\n",
    "    incident_zip VARCHAR(10),\n",
    "    city VARCHAR(255),\n",
    "    borough VARCHAR(255),\n",
    "    latitude FLOAT,\n",
    "    longitude FLOAT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "CREATE TABLE nyc_trees (\n",
    "    trees_id SERIAL PRIMARY KEY,\n",
    "    tree_id INTEGER,\n",
    "    block_id INTEGER,\n",
    "    status VARCHAR(255),\n",
    "    address VARCHAR(255),\n",
    "    zipcode VARCHAR(10),\n",
    "    zip_city VARCHAR(255),\n",
    "    latitude FLOAT,\n",
    "    longitude FLOAT,\n",
    "    x_sp FLOAT,\n",
    "    y_sp FLOAT,\n",
    "    geometry GEOMETRY(Point, 4326)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "CREATE TABLE nyc_historical_average_rents (\n",
    "    zillow_id SERIAL PRIMARY KEY,\n",
    "    region_id INTEGER,\n",
    "    region_name VARCHAR(255),\n",
    "    city VARCHAR(255),\n",
    "    state VARCHAR(255),\n",
    "    metro VARCHAR(255),\n",
    "    county_name VARCHAR(255),\n",
    "    january_2023 FLOAT,\n",
    "    february_2023 FLOAT,\n",
    "    march_2023 FLOAT,\n",
    "    april_2023 FLOAT,\n",
    "    may_2023 FLOAT,\n",
    "    june_2023 FLOAT,\n",
    "    july_2023 FLOAT,\n",
    "    august_2023 FLOAT,\n",
    "    september_2023 FLOAT\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using SQL (as opposed to SQLAlchemy), execute the schema files to create tables\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e194b",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c4934",
   "metadata": {},
   "source": [
    "#### Using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(tablename_to_dataframe):\n",
    "    # write INSERT statements or use pandas/geopandas to write SQL\n",
    "    engine = create_engine(DB_URL)\n",
    "    for table_name, dataframe in tablename_to_dataframe.items():\n",
    "        dataframe.to_sql(table_name, engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename_to_dataframe = {\n",
    "    \"zipcodes\": geodf_zipcode_data,\n",
    "    \"complaints\": geodf_311_data,\n",
    "    \"trees\": geodf_tree_data,\n",
    "    \"rents\": df_zillow_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530375af",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(tablename_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b9485",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567e8f4",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8eaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"FILL_ME_IN\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "FILL_ME_IN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c545f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce929adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071f6da",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a63e5b",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdcfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0dc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query your database for the data needed.\n",
    "    # You can put the data queried into a pandas/geopandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
